{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "what we've to do is:\n",
    "\n",
    "if(the encoded word has two parts):\n",
    "    -we cant really split it like a normal english word with suffix-mid-prefix, so we've to try to expand the begining, middle and ending properly\n",
    "    -split this and then encode the word now, without splitting it further.\n",
    "    -after getting the op of the transformer, try to fine tune the model using data that can be used to generate words that follow punarchi vidhi\n",
    "(ALWAYS CLEAR THE OUTPUT CELSS BEFORE PUSHING)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import re, collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for reading the file\n",
    "\"\"\"some wget thingy\"\"\"\n",
    "!wget https://raw.githubusercontent.com/Ishikahooda/Tamil-English-Dataset/master/Dataset/data.ta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('data.ta1', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns the mapping of words with their resp freqs\n",
    "def getStats(vocab):\n",
    "    #retunrs an empty dict with integer vals\n",
    "    pairs=collections.defaultdict(int)\n",
    "    #for loop that iterates through each word and in in the vocab dict\n",
    "    for word, freq in vocab.items():\n",
    "        #splits the words using an empty space character\n",
    "        symbols=word.split()\n",
    "        #iterates through the split words\n",
    "        for i in range(len(symbols)-1):\n",
    "            #updates the frequencies of occurrence of the current char with the next char\n",
    "            pairs[symbols[i], symbols[i+1]]+=freq\n",
    "    #the pairs after BPE is returned\n",
    "    return pairs\n",
    "\n",
    "#This returns a new vocab using the given pairs and vocab, where the pairs of words are merged together wherever they appear in the vocab \n",
    "def mergeVocab(pair, vocabIn):\n",
    "    #an empty dictionary that would contain the bit pairs after BPE\n",
    "    vocabOut={}\n",
    "    #the words are joined with the hidden escape character for each word\n",
    "    bigram=re.escape(' '.join(pair))\n",
    "    #the bigram regular exp is converted into a pattern obj\n",
    "    p=re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    #the words in the input vocab is iterated\n",
    "    for wordIn in vocabIn:\n",
    "        #replaces the occurrence of the given pair in p with the iterated word\n",
    "        wordOut=p.sub(''.join(pair), wordIn)\n",
    "        #for the key 'wordOut' in the output vocab dict, we have the value of the iterated word from the input vocab dict\n",
    "        vocabOut[wordOut]=vocabIn[wordIn]\n",
    "    #the output vocab dictionary is returned\n",
    "    return vocabOut\n",
    "\n",
    "#returns the vocan from the given document or string of words\n",
    "def getVocab(data):\n",
    "    #creates and empty dict with integer values\n",
    "    vocab=collections.defaultdict(int)\n",
    "    #iterating through each line of the document\n",
    "    for line in data:\n",
    "        #iterating through each word in the line\n",
    "        for word in line.split():\n",
    "            #the dict would be like -> ex: {'hello</w>':4, ...}\n",
    "            vocab[' '.join(list(word))+' <w>']+=1\n",
    "    #returns the vocab\n",
    "    return vocab\n",
    "\n",
    "#returns byte pair encoded vocab with the given corpus and max merged pairs\n",
    "def bytePairEnc(data, n):\n",
    "    #this returns the vocab from the given corpus\n",
    "    vocab=getVocab(data)\n",
    "    #this loop iterates for n timess\n",
    "    for _ in range(n):\n",
    "        #function that returns the mapping of words with their resp freqs with the given vocab\n",
    "        pairs=getStats(vocab)\n",
    "        #this returns the best pairs from the given vocab\n",
    "        topPairs=max(pairs, key=pairs.get)\n",
    "        #This returns a new vocab using the given pairs and vocab, where the pairs of words are merged together wherever they appear in the vocab \n",
    "        mergedVocab=mergeVocab(topPairs, vocab)\n",
    "    #returns the byte pair encoded vocab\n",
    "    return mergedVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the corpus and the number of merges\n",
    "corpus=text\n",
    "data=corpus.split('.')\n",
    "n=200\n",
    "bpePairs=bytePairEnc(data, n)\n",
    "print(bpePairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a dict with list vals for each word that represents word=word1+word2\n",
    "tamWords={\"மூதூர்\":[\"முதுமை\", \"ஊர்\"], \"பாசி\":[\"பசுமை\", \"இ\"], \"பைங்கொடி\":[\"பசுமை\", \"கொடி\"]}\n",
    "\n",
    "#try having a dict with completely different words that follow this trend. Try learning the trends in this to apply it in for new data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
